{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Pneumonia Detection using EfficientNetB0\n",
        "# Author: Sriraj Thiruchety\n",
        "# Description: Deep learning model using transfer learning to classify chest X-rays as either Normal or Pneumonia.\n"
      ],
      "metadata": {
        "id": "WAiDjEOxDPpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Authenticate and configure the Kaggle API to download datasets. Fetch the 'chest-xray-pneumonia' dataset and extract it into a local directory for further processing.\n"
      ],
      "metadata": {
        "id": "fyXIy-7OCP0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "GtliD1pDufbl",
        "outputId": "fbef2edd-b860-45bd-c382-6eb899e63141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload kaggle.json file from your Kaggle account\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5bed9263-b891-46dc-ae5b-1af27c1042f4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5bed9263-b891-46dc-ae5b-1af27c1042f4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# ✅ STEP 1: Install and Setup Kaggle API\n",
        "!pip install -q kaggle\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your kaggle.json file\n",
        "print(\"Upload kaggle.json file from your Kaggle account\")\n",
        "files.upload()\n",
        "\n",
        "# Set up the Kaggle API credentials\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load image files from extracted directories, resize them uniformly to match input shape requirements, assign labels based on folder names, and prepare a structured DataFrame for further use.\n"
      ],
      "metadata": {
        "id": "FKcG64-uCz1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 2: Download and Unzip Chest X-Ray Pneumonia Dataset from Kaggle\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "with zipfile.ZipFile(\"chest-xray-pneumonia.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"chest_xray\")\n",
        "\n",
        "# Verify folder contents\n",
        "print(\"Extracted folders:\", os.listdir(\"chest_xray\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8lLTu-buoQl",
        "outputId": "4932e1ba-c935-493b-e688-642a7a7d581c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Extracted folders: ['chest_xray']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the preprocessed dataset into training and validation subsets using stratification to preserve the proportion of classes in each set.\n"
      ],
      "metadata": {
        "id": "avTxftOaC14J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 3: Import Required Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "8fEJ2WNaut1s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training and validation data generators with real-time augmentation (e.g., rotations, zoom, flips) for improved generalization and to reduce overfitting.\n"
      ],
      "metadata": {
        "id": "ia5vxqy5C3Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 4: Define Paths and Set Image Parameters\n",
        "train_dir = \"chest_xray/chest_xray/train\"\n",
        "val_dir = \"chest_xray/chest_xray/val\"\n",
        "test_dir = \"chest_xray/chest_xray/test\"\n",
        "\n",
        "image_size = (224, 224)\n",
        "batch_size = 4\n"
      ],
      "metadata": {
        "id": "zp4tAexNu2_O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct a modular custom CNN architecture comprising convolutional blocks, batch normalization, pooling, and dropout layers for robust feature learning and classification.\n"
      ],
      "metadata": {
        "id": "CZ4hhSy_C4zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 5: Data Augmentation and Preprocessing\n",
        "\n",
        "# For training: apply augmentations\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# For validation and testing: only rescale\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow images from directories\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_gen = test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbrzh4KOu5qq",
        "outputId": "c5b92718-f75c-4893-ca21-7c36b4221bfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the CNN model using the Adam optimizer and categorical cross-entropy as the loss function. Include accuracy as a metric to monitor performance.\n"
      ],
      "metadata": {
        "id": "oYvRVYlIC6h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 6: Define Custom CNN Model Architecture\n",
        "def create_cnn(input_shape=(224, 224, 3), num_classes=2):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    # Classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_cnn()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Dp5XFLs8u7ri",
        "outputId": "b0006c59-0da1-4b12-8ee9-89e499c47a54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,785,026\u001b[0m (98.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,785,026</span> (98.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,784,578\u001b[0m (98.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,784,578</span> (98.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate class weights based on training data distribution and incorporate them into the training process to handle class imbalance.\n"
      ],
      "metadata": {
        "id": "UC8v1VZrC9gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 7: Define Callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.3, verbose=1)\n",
        "\n",
        "callbacks = [checkpoint, early_stop, reduce_lr]\n"
      ],
      "metadata": {
        "id": "HdYLiMYyvDp2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the CNN using the augmented training data. Apply callbacks like ModelCheckpoint, EarlyStopping, and ReduceLROnPlateau. Ensure all epochs execute for maximum accuracy.\n"
      ],
      "metadata": {
        "id": "L8XTNd54C_eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 8: Train the Model for all Epochs (no early stopping), aggressive LR reduction\n",
        "\n",
        "epochs = 30  # Increase epochs for more learning capacity\n",
        "\n",
        "# Only use ModelCheckpoint and ReduceLROnPlateau (no early stopping)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2, min_lr=1e-7, verbose=1)\n",
        "\n",
        "callbacks = [checkpoint, reduce_lr]\n",
        "\n",
        "# Start training\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=train_gen.samples // batch_size,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=val_gen.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYQae1uvFri",
        "outputId": "8e0a629d-38c3-449d-fb84-b838883f9e13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8629 - loss: 0.5929\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62500, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 84ms/step - accuracy: 0.8629 - loss: 0.5928 - val_accuracy: 0.6250 - val_loss: 1.5099 - learning_rate: 3.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9103 - loss: 0.2586\n",
            "Epoch 2: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 79ms/step - accuracy: 0.9103 - loss: 0.2586 - val_accuracy: 0.6250 - val_loss: 0.6467 - learning_rate: 3.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9125 - loss: 0.2137\n",
            "Epoch 3: val_accuracy did not improve from 0.62500\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 78ms/step - accuracy: 0.9125 - loss: 0.2137 - val_accuracy: 0.5000 - val_loss: 1.4311 - learning_rate: 3.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9292 - loss: 0.1854\n",
            "Epoch 4: val_accuracy improved from 0.62500 to 0.81250, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 80ms/step - accuracy: 0.9292 - loss: 0.1854 - val_accuracy: 0.8125 - val_loss: 0.3794 - learning_rate: 3.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9350 - loss: 0.1706\n",
            "Epoch 5: val_accuracy did not improve from 0.81250\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 79ms/step - accuracy: 0.9350 - loss: 0.1706 - val_accuracy: 0.6250 - val_loss: 0.8567 - learning_rate: 3.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9335 - loss: 0.1648\n",
            "Epoch 6: val_accuracy improved from 0.81250 to 0.87500, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9335 - loss: 0.1648 - val_accuracy: 0.8750 - val_loss: 0.3369 - learning_rate: 3.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9431 - loss: 0.1571\n",
            "Epoch 7: val_accuracy did not improve from 0.87500\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 78ms/step - accuracy: 0.9431 - loss: 0.1571 - val_accuracy: 0.8125 - val_loss: 0.3716 - learning_rate: 3.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9274 - loss: 0.2041\n",
            "Epoch 8: val_accuracy did not improve from 0.87500\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 6.000000284984708e-05.\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 79ms/step - accuracy: 0.9274 - loss: 0.2041 - val_accuracy: 0.7500 - val_loss: 0.8550 - learning_rate: 3.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9604 - loss: 0.1337\n",
            "Epoch 9: val_accuracy did not improve from 0.87500\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 79ms/step - accuracy: 0.9604 - loss: 0.1337 - val_accuracy: 0.5625 - val_loss: 1.7540 - learning_rate: 6.0000e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9589 - loss: 0.1241\n",
            "Epoch 10: val_accuracy improved from 0.87500 to 0.93750, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 81ms/step - accuracy: 0.9589 - loss: 0.1241 - val_accuracy: 0.9375 - val_loss: 0.2586 - learning_rate: 6.0000e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9600 - loss: 0.1131\n",
            "Epoch 11: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 78ms/step - accuracy: 0.9600 - loss: 0.1131 - val_accuracy: 0.7500 - val_loss: 0.4431 - learning_rate: 6.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9603 - loss: 0.1179\n",
            "Epoch 12: val_accuracy did not improve from 0.93750\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.2000000424450263e-05.\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 79ms/step - accuracy: 0.9603 - loss: 0.1178 - val_accuracy: 0.9375 - val_loss: 0.2743 - learning_rate: 6.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9627 - loss: 0.1039\n",
            "Epoch 13: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 79ms/step - accuracy: 0.9627 - loss: 0.1039 - val_accuracy: 0.8125 - val_loss: 0.3095 - learning_rate: 1.2000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9675 - loss: 0.1094\n",
            "Epoch 14: val_accuracy did not improve from 0.93750\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.4000000848900527e-06.\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 78ms/step - accuracy: 0.9675 - loss: 0.1094 - val_accuracy: 0.8125 - val_loss: 0.3054 - learning_rate: 1.2000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9601 - loss: 0.1038\n",
            "Epoch 15: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9601 - loss: 0.1038 - val_accuracy: 0.7500 - val_loss: 0.3433 - learning_rate: 2.4000e-06\n",
            "Epoch 16/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9641 - loss: 0.1035\n",
            "Epoch 16: val_accuracy did not improve from 0.93750\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.800000169780105e-07.\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 79ms/step - accuracy: 0.9641 - loss: 0.1035 - val_accuracy: 0.7500 - val_loss: 0.3746 - learning_rate: 2.4000e-06\n",
            "Epoch 17/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9647 - loss: 0.1061\n",
            "Epoch 17: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 80ms/step - accuracy: 0.9647 - loss: 0.1061 - val_accuracy: 0.7500 - val_loss: 0.3641 - learning_rate: 4.8000e-07\n",
            "Epoch 18/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9692 - loss: 0.0945\n",
            "Epoch 18: val_accuracy did not improve from 0.93750\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 79ms/step - accuracy: 0.9692 - loss: 0.0945 - val_accuracy: 0.7500 - val_loss: 0.3737 - learning_rate: 4.8000e-07\n",
            "Epoch 19/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9666 - loss: 0.0944\n",
            "Epoch 19: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 79ms/step - accuracy: 0.9666 - loss: 0.0944 - val_accuracy: 0.7500 - val_loss: 0.3743 - learning_rate: 1.0000e-07\n",
            "Epoch 20/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9657 - loss: 0.0971\n",
            "Epoch 20: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 80ms/step - accuracy: 0.9657 - loss: 0.0971 - val_accuracy: 0.7500 - val_loss: 0.3673 - learning_rate: 1.0000e-07\n",
            "Epoch 21/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9682 - loss: 0.0912\n",
            "Epoch 21: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9682 - loss: 0.0912 - val_accuracy: 0.7500 - val_loss: 0.3706 - learning_rate: 1.0000e-07\n",
            "Epoch 22/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9668 - loss: 0.0978\n",
            "Epoch 22: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 79ms/step - accuracy: 0.9668 - loss: 0.0978 - val_accuracy: 0.7500 - val_loss: 0.3598 - learning_rate: 1.0000e-07\n",
            "Epoch 23/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9663 - loss: 0.0956\n",
            "Epoch 23: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 80ms/step - accuracy: 0.9663 - loss: 0.0956 - val_accuracy: 0.7500 - val_loss: 0.3661 - learning_rate: 1.0000e-07\n",
            "Epoch 24/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9678 - loss: 0.0915\n",
            "Epoch 24: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9678 - loss: 0.0916 - val_accuracy: 0.7500 - val_loss: 0.3721 - learning_rate: 1.0000e-07\n",
            "Epoch 25/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9609 - loss: 0.1121\n",
            "Epoch 25: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 81ms/step - accuracy: 0.9609 - loss: 0.1121 - val_accuracy: 0.7500 - val_loss: 0.3700 - learning_rate: 1.0000e-07\n",
            "Epoch 26/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9611 - loss: 0.1033\n",
            "Epoch 26: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9611 - loss: 0.1033 - val_accuracy: 0.7500 - val_loss: 0.3695 - learning_rate: 1.0000e-07\n",
            "Epoch 27/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9549 - loss: 0.1262\n",
            "Epoch 27: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 79ms/step - accuracy: 0.9549 - loss: 0.1262 - val_accuracy: 0.7500 - val_loss: 0.3556 - learning_rate: 1.0000e-07\n",
            "Epoch 28/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9659 - loss: 0.0965\n",
            "Epoch 28: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 79ms/step - accuracy: 0.9659 - loss: 0.0965 - val_accuracy: 0.7500 - val_loss: 0.3540 - learning_rate: 1.0000e-07\n",
            "Epoch 29/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9632 - loss: 0.0985\n",
            "Epoch 29: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 80ms/step - accuracy: 0.9632 - loss: 0.0985 - val_accuracy: 0.7500 - val_loss: 0.3543 - learning_rate: 1.0000e-07\n",
            "Epoch 30/30\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9621 - loss: 0.1050\n",
            "Epoch 30: val_accuracy did not improve from 0.93750\n",
            "\u001b[1m1304/1304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 79ms/step - accuracy: 0.9621 - loss: 0.1050 - val_accuracy: 0.7500 - val_loss: 0.3575 - learning_rate: 1.0000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize training and validation performance using accuracy and loss curves to understand model learning behavior and convergence.\n"
      ],
      "metadata": {
        "id": "ZhucZ-PbDDaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 9: Evaluate Model on Test Set\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTEY3ftcxuKb",
        "outputId": "ec1209aa-e347-4033-d7a6-0abb11d21919"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.7536 - loss: 0.8372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdkqIR_NA6Z5",
        "outputId": "be7cd05e-f6aa-4087-eeb3-94a9eb059011"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload the best-performing model weights from the checkpoint to ensure the evaluation reflects the most optimal version of the trained model.\n"
      ],
      "metadata": {
        "id": "-zAIap7dDGLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 10: Load the best saved model\n",
        "from keras.models import load_model\n",
        "\n",
        "best_model = load_model(\"best_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD8d7fTuBGEP",
        "outputId": "84f5fdde-c2d8-471a-c336-36a7cce097ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the trained model to predict probabilities and final class labels for the validation set, preparing them for metrics computation.\n"
      ],
      "metadata": {
        "id": "ZWKN9nwlDHp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 11: Predict on validation data and print performance metrics\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict class probabilities\n",
        "y_pred_probs = best_model.predict(val_gen, steps=val_gen.samples // batch_size + 1)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = val_gen.classes\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=val_gen.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTh9Qoh4BeOX",
        "outputId": "818ebae0-f394-41a4-bcad-ef04e20080ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      NORMAL       0.29      0.25      0.27         8\n",
            "   PNEUMONIA       0.33      0.38      0.35         8\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.31      0.31      0.31        16\n",
            "weighted avg       0.31      0.31      0.31        16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model on the validation set using a classification report and confusion matrix to analyze accuracy and class-wise performance.\n"
      ],
      "metadata": {
        "id": "7koZ-0JJDKJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 12: Plot confusion matrix to visualize class-wise performance\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = list(val_gen.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "2skdF3xqBhZL",
        "outputId": "ba9e8f2a-a6bd-491a-99d1-06f4ed699c4a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}